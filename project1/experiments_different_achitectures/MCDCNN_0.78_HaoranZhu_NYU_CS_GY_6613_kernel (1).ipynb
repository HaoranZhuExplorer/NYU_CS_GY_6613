{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Project Summary**</font><br>\nIn this competition, the main task is to do surface time series classification. 1d convolution is a good technique when doing the time series classification job. So I apply 1d convolutional neural network to solve this problem. The whole code is written in Pytorch."},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**External libs we are using**</font><br>"},{"metadata":{"_uuid":"a6ed998e-ee9a-4333-8332-8fa753b7f0d4","_cell_guid":"e6e0bc2b-9cba-4688-9e0b-15f11d219c2d","trusted":true},"cell_type":"code","source":"# libs we are using\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import TensorDataset, DataLoader","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"b8906e48-2384-4bb3-bba7-722160428e39","_cell_guid":"295d38d1-6663-4575-93ba-c6cfac9f6129","trusted":true},"cell_type":"markdown","source":"<font size=\"5\">**Data preparations**</font><br>\n\nIn this project, I use the raw data as input of the network. I concatenated all datasets into one single numpy array. The first 3810 rows are training data with given labels, the rest 3816 rows are testing data where labels are not given. In total raw data has 7816 rows. In addition to that, we split the raw training data into training data and validation data by the ratio of 80/20.\n\n\nI create three datasets and data loaders for them to make the data ready for model's training. The process is straightforward. I split the labelled data into two subsets, and keep testing data as is. Also, I convert Numpy arrays into `torch.tensor` objects of proper type (float for samples, and long - for targets).\n"},{"metadata":{"_uuid":"94c41c8d-0c91-4aa1-83a4-ff3f518f35f4","_cell_guid":"88b9ec00-fc64-4040-896b-895d06cd58f2","trusted":true},"cell_type":"code","source":"def create_datasets(data, target, train_size, valid_pct=0.2, seed=None):\n    \"\"\"Converts NumPy arrays into PyTorch datsets.\n    \n    Three datasets are created in total:\n        * training dataset\n        * validation dataset\n        * testing (un-labelled) dataset\n\n    \"\"\"\n    raw =  data\n    sz = train_size\n    idx = np.arange(sz)\n    trn_idx, val_idx = train_test_split(\n        idx, test_size=valid_pct, random_state=seed)\n     \n    trn_ds = TensorDataset(\n        torch.tensor(raw[:sz][trn_idx]).float(), \n        torch.tensor(target[:sz][trn_idx]).long())\n    val_ds = TensorDataset(\n        torch.tensor(raw[:sz][val_idx]).float(), \n        torch.tensor(target[:sz][val_idx]).long())\n    tst_ds = TensorDataset(\n        torch.tensor(raw[sz:]).float(), \n        torch.tensor(target[sz:]).long())\n    return trn_ds, val_ds, tst_ds\n\n# We use this function to divide the data\ndef create_datasets2(data_arr, train_size, valid_pct=0.2, seed=None):\n    \"\"\"Converts NumPy arrays into PyTorch datsets.\n    \n    Three datasets are created in total:\n        * training dataset\n        * validation dataset\n        * testing (un-labelled) dataset\n\n    \"\"\"\n    raw =  data_arr\n    sz = train_size\n\n    idx = np.arange(sz)\n    print(\"total data length\")\n    print(len(idx))\n    trn_idx, tst_idx = train_test_split(idx, test_size=0.2, random_state=1)\n    trn_idx, val_idx = train_test_split(trn_idx, test_size=0.25, random_state=1)\n    \n    print(\"input one dimension shape\")\n    print(raw[0].shape)\n    print(\"training data length\")\n    print(len(trn_idx))\n    print(\"validation data le\")\n    print(len(val_idx))\n    print(\"testing d\")\n    print(len(tst_idx))\n    \n    trn_ds = TensorDataset(\n        torch.tensor(raw[0][:sz][trn_idx]).float(),\n        torch.tensor(raw[1][:sz][trn_idx]).float(),\n        torch.tensor(raw[2][:sz][trn_idx]).float(),\n        torch.tensor(raw[3][:sz][trn_idx]).float(),\n        torch.tensor(raw[4][:sz][trn_idx]).float(),\n        torch.tensor(raw[5][:sz][trn_idx]).float(),\n        torch.tensor(raw[6][:sz][trn_idx]).float(),\n        torch.tensor(raw[7][:sz][trn_idx]).float(),\n        torch.tensor(raw[8][:sz][trn_idx]).float(),\n        torch.tensor(target[:sz][trn_idx]).long())\n    \n    val_ds = TensorDataset(\n        torch.tensor(raw[0][:sz][val_idx]).float(),\n        torch.tensor(raw[1][:sz][val_idx]).float(), \n        torch.tensor(raw[2][:sz][val_idx]).float(), \n        torch.tensor(raw[3][:sz][val_idx]).float(), \n        torch.tensor(raw[4][:sz][val_idx]).float(), \n        torch.tensor(raw[5][:sz][val_idx]).float(), \n        torch.tensor(raw[6][:sz][val_idx]).float(), \n        torch.tensor(raw[7][:sz][val_idx]).float(), \n        torch.tensor(raw[8][:sz][val_idx]).float(), \n        torch.tensor(target[:sz][val_idx]).long())\n    \n    tst_ds = TensorDataset(\n        torch.tensor(raw[0][:sz][tst_idx]).float(),\n        torch.tensor(raw[1][:sz][tst_idx]).float(),\n        torch.tensor(raw[2][:sz][tst_idx]).float(),\n        torch.tensor(raw[3][:sz][tst_idx]).float(),\n        torch.tensor(raw[4][:sz][tst_idx]).float(),\n        torch.tensor(raw[5][:sz][tst_idx]).float(),\n        torch.tensor(raw[6][:sz][tst_idx]).float(),\n        torch.tensor(raw[7][:sz][tst_idx]).float(),\n        torch.tensor(raw[8][:sz][tst_idx]).float(),\n        torch.tensor(target[:sz][tst_idx]).long())\n    \n    return trn_ds, val_ds, tst_ds\n\ndef create_loaders(data, bs=128, jobs=0):\n    \"\"\"Wraps the datasets returned by create_datasets function with data loaders.\"\"\"\n    \n    trn_ds, val_ds, tst_ds = data\n    trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True, num_workers=jobs)\n    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n    tst_dl = DataLoader(tst_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n    return trn_dl, val_dl, tst_dl","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Neural Network Architecture**</font><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flatten(nn.Module):\n    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n\n    def __init__(self, keep_batch_dim=True):\n        super().__init__()\n        self.keep_batch_dim = keep_batch_dim\n\n    def forward(self, x):\n        if self.keep_batch_dim:\n            return x.view(x.size(0), -1)\n        return x.view(-1)","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"f144e459-53bb-4b5a-860d-abec117fc2cc","_cell_guid":"07870588-c88f-42ff-b782-5ae3c5e6e568","trusted":true},"cell_type":"code","source":"class Surface_Classifier(nn.Module):\n    def __init__(self, raw_ni, no, drop=.5):\n        super().__init__()\n        \n        self.conv1d_channel_0 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n            \n           \n        \n        )\n            \n            \n        \n        self.conv1d_channel_1 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n        \n        self.conv1d_channel_2 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n        \n        self.conv1d_channel_3 = nn.Sequential(\n             nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n        \n        self.conv1d_channel_4 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n        \n        self.conv1d_channel_5 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n        \n        self.conv1d_channel_6 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n           \n        )\n        \n        self.conv1d_channel_7 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n            \n\n       \n        \n        self.conv1d_channel_8 = nn.Sequential(\n            nn.Conv1d(1, 8, 16, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n\n            nn.Conv1d(8, 16, 11, 3, 3),\n            nn.ReLU(),\n            nn.Dropout(),\n            \n            nn.MaxPool1d(kernel_size=2),\n        )\n\n            \n\n        self.dense = nn.Sequential(\n            nn.Linear(432, 324),  nn.ReLU(),nn.Dropout(),\n            nn.Linear(324, 36),  nn.ReLU(),nn.Dropout(),\n            nn.Linear(36, no),  nn.ReLU()\n        )\n        \n            \n\n    def forward(self, t_channel_0, t_channel_1, t_channel_2, t_channel_3, t_channel_4, t_channel_5, t_channel_6, t_channel_7, t_channel_8):\n        conv1d_out_channel_0 = self.conv1d_channel_0(t_channel_0)\n        conv1d_out_channel_1 = self.conv1d_channel_1(t_channel_1)\n        conv1d_out_channel_2 = self.conv1d_channel_2(t_channel_2)\n        conv1d_out_channel_3 = self.conv1d_channel_3(t_channel_3)\n        conv1d_out_channel_4 = self.conv1d_channel_4(t_channel_4)\n        conv1d_out_channel_5 = self.conv1d_channel_5(t_channel_5)\n        conv1d_out_channel_6 = self.conv1d_channel_6(t_channel_6)\n        conv1d_out_channel_7 = self.conv1d_channel_7(t_channel_7)\n        conv1d_out_channel_8 = self.conv1d_channel_8(t_channel_8)\n        \n        t_in = torch.cat([conv1d_out_channel_0,conv1d_out_channel_1, conv1d_out_channel_2, conv1d_out_channel_3, conv1d_out_channel_4, conv1d_out_channel_5, conv1d_out_channel_6, conv1d_out_channel_7, conv1d_out_channel_8], dim=1)\n        res = t_in.view(t_in.size(0), -1)\n        out = self.dense(res)\n        return out\n        ","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Initial setup for random seed and project path**</font><br>"},{"metadata":{"_uuid":"b4b74c47-df3d-4201-93a7-f8cb79d6a652","_cell_guid":"aa2ea0fc-dfc2-436e-9a73-aab6bfb63d20","trusted":true},"cell_type":"code","source":"\n# set up the seed\nseed = 1\nnp.random.seed(seed)\n\n# path to sample submission\nsample = Path.cwd().parent/'input'/'career-con-2019'/'sample_submission.csv'\n\nROOT = Path.cwd().parent/'input'/'career-con-2019-preprocessed-data'\nraw_arr = np.load(ROOT/'feat.npy').transpose(0, 2, 1)\ntarget = np.load(ROOT/'target.npy')\n\nraw_dim_data = [None]*9\n#print(raw_dim_data)\nfor i in range(0, 9):\n    raw_dim_data[i] = raw_arr[:,i,:]\n#    print(\"raw data shape\")\n    \n    raw_dim_data[i] = raw_dim_data[i].reshape([7626,1,128])\n#    print(raw_dim_data[i].shape)\n    \n# print(\"raw array shape\")\n# print(raw_arr.shape)\n# print(\"label array shape\")\n# print(target.shape)\n\ntrn_sz = 3810  # only the first `trn_sz` rows in each array include labelled data\n#datasets = create_datasets((raw_arr), target, trn_sz, seed=seed)\ndatasets = create_datasets2((raw_dim_data), trn_sz, seed=seed)\n\n\n# make sure that we run on a proper device (not relevant for Kaggle kernels but helpful in Jupyter sessions)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n\ntrn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256)","execution_count":38,"outputs":[{"output_type":"stream","text":"total data length\n3810\ninput one dimension shape\n(7626, 1, 128)\ntraining data length\n2286\nvalidation data le\n762\ntesting d\n762\n","name":"stdout"}]},{"metadata":{"_uuid":"b9026a32-1355-4689-8bf9-581a5228af69","_cell_guid":"5db66d39-80aa-48f4-9aab-4f44eace0192","trusted":true},"cell_type":"markdown","source":"<font size=\"5\">**Training model**</font><br>\nNow everything is ready to create a training loop and see if our model works. For each training epoch, the loop performs the following actions:\n1. train model on the `trn_ds` dataset;\n2. verify quality on the `val_ds` dataset;\n3. check if the quality improved since previous epoch, and if so, save the model's weights onto disk;\n4. in case if the model's quality isn't impoving for `patience` epochs, the training is stopped.\nAlso, the code tracks loss and accuracy history, and prints current scores with exponentially increasing logging frequency, i.e., only at 1, 2, 4, 8... epochs."},{"metadata":{"_uuid":"dee51d07-1cff-4db3-a87d-bebc4bf5bcc0","_cell_guid":"72095ada-fe94-4757-9a8a-918481b04336","trusted":true},"cell_type":"code","source":"raw_feat = raw_arr.shape[1]\n\n\nlr = 0.002\nn_epochs = 10000\niterations_per_epoch = len(trn_dl)\nnum_classes = 9\nbest_acc = 0\npatience, trials = 500, 0\nbase = 1\nstep = 2\nloss_history = []\nacc_history = []\n\nmodel = Surface_Classifier(raw_feat, num_classes).to(device)\nmodel.cuda()\ncriterion = nn.CrossEntropyLoss(reduction='sum')\nopt = optim.Adam(model.parameters(), lr=lr)\n\nprint('Start model training')\n\nfor epoch in range(1, n_epochs + 1):\n    \n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(trn_dl):\n        #x_raw, y_batch = [t.to(device) for t in batch]\n        x_channel_0, x_channel_1,  x_channel_2,  x_channel_3,  x_channel_4,  x_channel_5,  x_channel_6,  x_channel_7,  x_channel_8, y_batch = [t.to(device) for t in batch]\n        opt.zero_grad()\n        \n#         print(\"channel 0 type\")\n#         print(type(x_channel_0))\n#         print(\"channel 0 shape\")\n#         print(x_channel_0.shape)\n#         print(\"batch type\")\n#         print(type(batch))\n#         print(len(batch))\n#         print(batch[0].shape)\n#         print(batch[9].shape)\n\n        out = model(x_channel_0, x_channel_1, x_channel_2, x_channel_3, x_channel_4, x_channel_5, x_channel_6, x_channel_7, x_channel_8)\n        \n        \n#         out = []\n#         with torch.no_grad():\n#             for x_channel_0, x_channel_1,  x_channel_2,  x_channel_3,  x_channel_4,  x_channel_5,  x_channel_6,  x_channel_7,  x_channel_8, y_batch in batch:\n#                 output = model(x_channel_0, x_channel_1, x_channel_2, x_channel_3, x_channel_4, x_channel_5, x_channel_6, x_channel_7, x_channel_8)\n#                 out.append(output.detach())\n#         out = torch.cat(out)\n        \n\n    \n        loss = criterion(out, y_batch)\n        epoch_loss += loss.item()\n        loss.backward()\n        opt.step()\n        \n    epoch_loss /= trn_sz\n    loss_history.append(epoch_loss)\n    \n    model.eval()\n    correct, total = 0, 0\n    \n    for batch in val_dl:\n        x_channel_0, x_channel_1,  x_channel_2,  x_channel_3,  x_channel_4,  x_channel_5,  x_channel_6,  x_channel_7,  x_channel_8, y_batch = [t.to(device) for t in batch]\n        \n        out = model(x_channel_0, x_channel_1, x_channel_2, x_channel_3, x_channel_4, x_channel_5, x_channel_6, x_channel_7, x_channel_8)\n        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n        total += y_batch.size(0)\n        correct += (preds == y_batch).sum().item()\n    \n    acc = correct / total\n    acc_history.append(acc)\n\n    if epoch % base == 0:\n        print(f'Epoch: {epoch:3d}. Loss: {epoch_loss:.4f}. Acc.: {acc:2.2%}')\n        base *= step\n    print(f'Epoch: {epoch:3d}. Loss: {epoch_loss:.4f}. Acc.: {acc:2.2%}')\n\n    \n    if acc > best_acc:\n        trials = 0\n        best_acc = acc\n        torch.save(model.state_dict(), 'best.pth')\n        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n    else:\n        trials += 1\n        if trials >= patience:\n            print(f'Early stopping on epoch {epoch}')\n            break\n            \nprint('Done!')","execution_count":39,"outputs":[{"output_type":"stream","text":"Start model training\n","name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"size mismatch, m1: [256 x 432], m2: [576 x 324] at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THC/generic/THCTensorMathBlas.cu:266","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-2ce3acc8625d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#         print(batch[9].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_channel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_channel_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-056910d72759>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t_channel_0, t_channel_1, t_channel_2, t_channel_3, t_channel_4, t_channel_5, t_channel_6, t_channel_7, t_channel_8)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mt_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv1d_out_channel_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv1d_out_channel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_out_channel_8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [256 x 432], m2: [576 x 324] at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THC/generic/THCTensorMathBlas.cu:266"]}]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Compute result on testing data**</font><br>"},{"metadata":{"_uuid":"d0f483d5-5542-4d65-a70f-1aa7b3e13c3c","_cell_guid":"05b2b8d9-2b63-436e-a906-a839fb008c0e","trusted":true},"cell_type":"code","source":"test_results = []\nmodel.load_state_dict(torch.load('best.pth'))\nmodel.eval()\n\n# for batch in val_dl:\n#     x_raw, y_batch = [t.to(device) for t in batch]\n#     out = model(x_raw)\n#     preds = F.log_softmax(out, dim=1).argmax(dim=1)\n#     total += y_batch.size(0)\n#     correct += (preds == y_batch).sum().item()\n#     acc = correct / total\n#     acc_history.append(acc)\n\n# for batch in tst_dl:\n#     x, y_batche = [t.to(device) for t in (batch)]\n#     out = model(x)\n#     y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n#     test_results.extend(y_hat.tolist())\n    \nfor batch in tst_dl:\n        x_raw, y_batch = [t.to(device) for t in batch]\n        out = model(x_channel_0, x_channel_1, x_channel_2, x_channel_3, x_channel_4, x_channel_5, x_channel_6, x_channel_7, x_channel_8)\n        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n        total += y_batch.size(0)\n        correct += (preds == y_batch).sum().item()\n    \nacc = correct / total\nprint(\"accurancy on test data: \"+str(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Store final result**</font><br>"},{"metadata":{"_uuid":"7a49a38e-e203-4884-ba78-33fe8aa02426","_cell_guid":"f4bd2628-c801-42d5-9af6-11bbd89f2352","trusted":true},"cell_type":"code","source":"'''\nsubmit = pd.read_csv(sample)\nenc = joblib.load(ROOT/'encoder.model')\nsubmit['surface'] = enc.inverse_transform(test_results)\nsubmit.to_csv('submit_base.csv', index=None)\nprint(\"store result successfully!\")\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}