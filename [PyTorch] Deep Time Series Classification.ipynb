{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"# %% [markdown]\n# # Deep Time Series Classification\n# \n# The time series classification problem seems to be a great choice to apply Deep Learning models. However, even deep models cannot magically give you good results if the data wasn't propertly prepared. \n# \n# The [CareerCon 2019 competition](https://www.kaggle.com/c/career-con-2019) was all about time series classification. In [one of my previous kernels](https://www.kaggle.com/purplejester/a-simple-lstm-based-time-series-classifier), I've tried to apply LSTM model to the dataset and didn't get too impressive accuracy. Also, I was experimenting with 1-d convolutions but again without any luck. So finally, I decided to go with [a more simple apporach](https://www.kaggle.com/purplejester/the-best-friend-of-an-alchemist). Nevertheless, when the competition was ended, [one of the best solutions](https://www.kaggle.com/prith189/starter-code-for-3rd-place-solution) implemented by [prith189](https://www.kaggle.com/prith189) uses Deep Learning to achieve a decent result on both public and private leaderboard.\n# \n# In this notebook, we're going to use PyTorch to create a clone of the mentioned solution and see if we can improve it a bit using modern training techniques.\n# \n# <img src=\"https://i.imgur.com/XWrG9ys.png\" width=\"500\"></img>\n# \n# ## Imports\n# \n# In addition to PyTorch, we use \"standard\" Python's data science stack. Also, there are couple of additional functions from the standard library used in utils and snippets.\n\n# %% [code]\nfrom collections import defaultdict\nfrom functools import partial\nfrom multiprocessing import cpu_count\nfrom pathlib import Path\nfrom textwrap import dedent\n\n# %% [code]\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.externals import joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.nn import functional as F\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# %% [code]\nseed = 1\nnp.random.seed(seed)\n\n# %% [code]\n# path to sample submission\nsample = Path.cwd().parent/'input'/'career-con-2019'/'sample_submission.csv'\n\n# %% [markdown]\n# ## Reading The Preprocessed Dataset\n# \n# As it was already mentioned above, we use a preprocessed data from [this kernel](https://www.kaggle.com/prith189/starter-code-for-3rd-place-solution) to train our models. The preprocessed data was added as a custom dataset. The major differences from the \"raw\" data:\n# 1. the `orientaion_[XYZW]` columns were converted into Euler angles (original columns were dropped);\n# 2. each measurment sequence was shifted to have zero mean;\n# 3. the whole dataset was normalized into `[-1, +1]` range;\n# 4. the linear and angular accelerations and velocities were processed with `np.fft.rfft` call and saved as an _additional_ dataset to extend the original data.\n\n# %% [code]\nROOT = Path.cwd().parent/'input'/'career-con-2019-preprocessed-data'\nenc = joblib.load(ROOT/'encoder.model')\nraw_arr = np.load(ROOT/'feat.npy').transpose(0, 2, 1)\nfft_arr = np.load(ROOT/'feat_fft.npy').transpose(0, 2, 1)\ntarget = np.load(ROOT/'target.npy')\nprint(dedent(f'''\nDataset shapes:\n    raw: {raw_arr.shape}\n    fft: {fft_arr.shape}\n    target: {target.shape}\n'''))\n\n# %% [markdown]\n# Please note that the testing and training data are concatenated into a single Numpy array. The first `3810` rows are the training samples. The rest of rows represent the testing data with dummy labels.\n# \n# ## PyTorch Datasets and Data Loaders\n# \n# We create three datasets and data loaders for them to make the data ready for model's training. The process is straightforward. We split the labelled data into two subsets, and keep testing data as is. Also, we convert Numpy arrays into `torch.tensor` objects of proper type (float for samples, and long - for targets).\n\n# %% [code]\ndef create_datasets(data, target, train_size, valid_pct=0.1, seed=None):\n    \"\"\"Converts NumPy arrays into PyTorch datsets.\n    \n    Three datasets are created in total:\n        * training dataset\n        * validation dataset\n        * testing (un-labelled) dataset\n\n    \"\"\"\n    raw, fft = data\n    assert len(raw) == len(fft)\n    sz = train_size\n    idx = np.arange(sz)\n    trn_idx, val_idx = train_test_split(\n        idx, test_size=valid_pct, random_state=seed)\n    trn_ds = TensorDataset(\n        torch.tensor(raw[:sz][trn_idx]).float(), \n        torch.tensor(fft[:sz][trn_idx]).float(), \n        torch.tensor(target[:sz][trn_idx]).long())\n    val_ds = TensorDataset(\n        torch.tensor(raw[:sz][val_idx]).float(), \n        torch.tensor(fft[:sz][val_idx]).float(), \n        torch.tensor(target[:sz][val_idx]).long())\n    tst_ds = TensorDataset(\n        torch.tensor(raw[sz:]).float(), \n        torch.tensor(fft[sz:]).float(), \n        torch.tensor(target[sz:]).long())\n    return trn_ds, val_ds, tst_ds\n\n# %% [code]\ndef create_loaders(data, bs=128, jobs=0):\n    \"\"\"Wraps the datasets returned by create_datasets function with data loaders.\"\"\"\n    \n    trn_ds, val_ds, tst_ds = data\n    trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True, num_workers=jobs)\n    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n    tst_dl = DataLoader(tst_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n    return trn_dl, val_dl, tst_dl\n\n# %% [markdown]\n# Next, we're going to create a couple of helper classes to build a classifier. The `torch` framework doesn't have a dedicated `SeparableConv` layers. But we easily can replicate them with the following class. (Which was taken from one of the PyTorch forum's threads). As the code below shows, the separable convolution is a pretty simple thing: two convolutions following one another. The major purpose of this type of layer is to [reduce the number of model's parameters](https://arxiv.org/pdf/1704.04861.pdf).\n\n# %% [code]\nclass _SepConv1d(nn.Module):\n    \"\"\"A simple separable convolution implementation.\n    \n    The separable convlution is a method to reduce number of the parameters \n    in the deep learning network for slight decrease in predictions quality.\n    \"\"\"\n    def __init__(self, ni, no, kernel, stride, pad):\n        super().__init__()\n        self.depthwise = nn.Conv1d(ni, ni, kernel, stride, padding=pad, groups=ni)\n        self.pointwise = nn.Conv1d(ni, no, kernel_size=1)\n\n    def forward(self, x):\n        return self.pointwise(self.depthwise(x))\n\n# %% [markdown]\n# Also, we extend a bit the separable convolution layer with activation layer and dropout to simplify the layers initialization process and reduce the number of code lines in the model.\n\n# %% [code]\nclass SepConv1d(nn.Module):\n    \"\"\"Implementes a 1-d convolution with 'batteries included'.\n    \n    The module adds (optionally) activation function and dropout layers right after\n    a separable convolution layer.\n    \"\"\"\n    def __init__(self, ni, no, kernel, stride, pad, drop=None,\n                 activ=lambda: nn.ReLU(inplace=True)):\n    \n        super().__init__()\n        assert drop is None or (0.0 < drop < 1.0)\n        layers = [_SepConv1d(ni, no, kernel, stride, pad)]\n        if activ:\n            layers.append(activ())\n        if drop is not None:\n            layers.append(nn.Dropout(drop))\n        self.layers = nn.Sequential(*layers)\n        \n    def forward(self, x): \n        return self.layers(x)\n\n# %% [markdown]\n# The `Flatten` layer replicates `Reshape` layer from `Keras` and makes the convolution layer output ready to pass them into `nn.Linear` layers.\n\n# %% [code]\nclass Flatten(nn.Module):\n    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n\n    def __init__(self, keep_batch_dim=True):\n        super().__init__()\n        self.keep_batch_dim = keep_batch_dim\n\n    def forward(self, x):\n        if self.keep_batch_dim:\n            return x.view(x.size(0), -1)\n        return x.view(-1)\n\n# %% [markdown]\n# Finally, we create our classifier using the layers created above. As you see, the model consists of two separate \"paths\" which output is concatenated and then passed into the top layers. One path uses the \"raw\" data, and the second one - the data processed with FFT. Therefore, we don't drop the original data but use it in addition to the processed observations.\n\n# %% [code]\nclass Classifier(nn.Module):\n    def __init__(self, raw_ni, fft_ni, no, drop=.5):\n        super().__init__()\n        \n        self.raw = nn.Sequential(\n            SepConv1d(raw_ni,  32, 8, 2, 3, drop=drop),\n            SepConv1d(    32,  64, 8, 4, 2, drop=drop),\n            SepConv1d(    64, 128, 8, 4, 2, drop=drop),\n            SepConv1d(   128, 256, 8, 4, 2),\n            Flatten(),\n            nn.Dropout(drop), nn.Linear(256, 64), nn.ReLU(inplace=True),\n            nn.Dropout(drop), nn.Linear( 64, 64), nn.ReLU(inplace=True))\n        \n        self.fft = nn.Sequential(\n            SepConv1d(fft_ni,  32, 8, 2, 4, drop=drop),\n            SepConv1d(    32,  64, 8, 2, 4, drop=drop),\n            SepConv1d(    64, 128, 8, 4, 4, drop=drop),\n            SepConv1d(   128, 128, 8, 4, 4, drop=drop),\n            SepConv1d(   128, 256, 8, 2, 3),\n            Flatten(),\n            nn.Dropout(drop), nn.Linear(256, 64), nn.ReLU(inplace=True),\n            nn.Dropout(drop), nn.Linear( 64, 64), nn.ReLU(inplace=True))\n        \n        self.out = nn.Sequential(\n            nn.Linear(128, 64), nn.ReLU(inplace=True), nn.Linear(64, no))\n        \n    def forward(self, t_raw, t_fft):\n        raw_out = self.raw(t_raw)\n        fft_out = self.fft(t_fft)\n        t_in = torch.cat([raw_out, fft_out], dim=1)\n        out = self.out(t_in)\n        return out\n\n# %% [code]\ntrn_sz = 3810  # only the first `trn_sz` rows in each array include labelled data\n\n# %% [code]\ndatasets = create_datasets((raw_arr, fft_arr), target, trn_sz, seed=seed)\n\n# %% [code]\n# make sure that we run on a proper device (not relevant for Kaggle kernels but helpful in Jupyter sessions)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# %% [markdown]\n# Now everything is ready to create a training loop and see if our model works. For each training epoch, the loop performs the following actions:\n# 1. train model on the `trn_ds` dataset;\n# 2. verify quality on the `val_ds` dataset;\n# 3. check if the quality improved since previous epoch, and if so, save the model's weights onto disk;\n# 4. in case if the model's quality isn't impoving for `patience` epochs, the training is stopped.\n# \n# Also, the code tracks loss and accuracy history, and prints current scores with exponentially increasing logging frequency, i.e., only at 1, 2, 4, 8... epochs.\n\n# %% [code]\nraw_feat = raw_arr.shape[1]\nfft_feat = fft_arr.shape[1]\n\ntrn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256)\n\nlr = 0.001\nn_epochs = 3000\niterations_per_epoch = len(trn_dl)\nnum_classes = 9\nbest_acc = 0\npatience, trials = 500, 0\nbase = 1\nstep = 2\nloss_history = []\nacc_history = []\n\nmodel = Classifier(raw_feat, fft_feat, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss(reduction='sum')\nopt = optim.Adam(model.parameters(), lr=lr)\n\nprint('Start model training')\n\nfor epoch in range(1, n_epochs + 1):\n    \n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(trn_dl):\n        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n        opt.zero_grad()\n        out = model(x_raw, x_fft)\n        loss = criterion(out, y_batch)\n        epoch_loss += loss.item()\n        loss.backward()\n        opt.step()\n        \n    epoch_loss /= trn_sz\n    loss_history.append(epoch_loss)\n    \n    model.eval()\n    correct, total = 0, 0\n    for batch in val_dl:\n        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n        out = model(x_raw, x_fft)\n        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n        total += y_batch.size(0)\n        correct += (preds == y_batch).sum().item()\n    \n    acc = correct / total\n    acc_history.append(acc)\n\n    if epoch % base == 0:\n        print(f'Epoch: {epoch:3d}. Loss: {epoch_loss:.4f}. Acc.: {acc:2.2%}')\n        base *= step\n\n    if acc > best_acc:\n        trials = 0\n        best_acc = acc\n        torch.save(model.state_dict(), 'best.pth')\n        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n    else:\n        trials += 1\n        if trials >= patience:\n            print(f'Early stopping on epoch {epoch}')\n            break\n            \nprint('Done!')\n\n# %% [markdown]\n# Now we can plot the training history and run the model on the testing dataset.\n\n# %% [code]\ndef smooth(y, box_pts):\n    box = np.ones(box_pts)/box_pts\n    y_smooth = np.convolve(y, box, mode='same')\n    return y_smooth\n\n# %% [code]\nf, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nax[0].plot(loss_history, label='loss')\nax[0].set_title('Validation Loss History')\nax[0].set_xlabel('Epoch no.')\nax[0].set_ylabel('Loss')\n\nax[1].plot(smooth(acc_history, 5)[:-2], label='acc')\nax[1].set_title('Validation Accuracy History')\nax[1].set_xlabel('Epoch no.')\nax[1].set_ylabel('Accuracy');\n\n# %% [code]\ntest_results = []\nmodel.load_state_dict(torch.load('best.pth'))\nmodel.eval()\nfor x_raw, x_fft, _ in tst_dl:\n    batches = [t.to(device) for t in (x_raw, x_fft)]\n    out = model(*batches)\n    y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n    test_results.extend(y_hat.tolist())\n\n# %% [code]\nsubmit = pd.read_csv(sample)\nsubmit['surface'] = enc.inverse_transform(test_results)\nsubmit.to_csv('submit_base.csv', index=None)","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}